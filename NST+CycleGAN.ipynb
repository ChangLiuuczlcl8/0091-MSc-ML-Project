{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NST+CycleGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZm4NW5-DlT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import IPython\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import scipy.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh9inwaFQjiD",
        "colab_type": "code",
        "outputId": "f3d4cbad-fc0d-448e-cd3c-52bf22625e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Qu08kLQje6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown Parameters\n",
        "ngf = 64 # Number of filters in first layer of generator \n",
        "ndf = 64 # Number of filters in first layer of discriminator \n",
        "stddev = 0.02 # std of Gaussian distribution\n",
        "batch_size = 1 # batch_size \n",
        "pool_size = 50 # pool_size \n",
        "img_width = 64 # Imput image will of width 256 \n",
        "img_height = 64 # Input image will be of height 256 \n",
        "img_depth = 3 # RGB format\n",
        "to_restore = False\n",
        "vgg_layers = scipy.io.loadmat('/content/gdrive/My Drive/MSc ML/0091/vgg19.mat')[\"layers\"]\n",
        "check_dir = '/content/gdrive/My Drive/MSc ML/0091/64x64/checkpoint/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviwqpwpQjY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def general_conv2d(inputconv, num_features=64, \n",
        "                   window_height=7, window_width=7, \n",
        "                   stride_height=1, stride_width=1, \n",
        "                   padding_size=1, name=\"conv2d\"):\n",
        "    with tf.variable_scope(name):\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size,], [padding_size, padding_size], [0, 0]])\n",
        "        inputconv_ = tf.pad(inputconv, paddings, \"REFLECT\")\n",
        "        conv = tf.contrib.layers.conv2d(inputconv_, num_features, [window_height, window_width], \n",
        "                                        [stride_height, stride_width], padding='VALID', activation_fn=None, \n",
        "                                        weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                                        biases_initializer=tf.constant_initializer(0.0))\n",
        "        return conv\n",
        "\n",
        "      \n",
        "def general_deconv2d(inputconv, num_features=64, \n",
        "                     window_height=3, window_width=3, \n",
        "                     stride_height=2, stride_width=2, \n",
        "                     padding_size=1, name=\"deconv2d\"):\n",
        "    with tf.variable_scope(name):\n",
        "        size = tf.shape(inputconv)[1]\n",
        "        inputconv = tf.image.resize_nearest_neighbor(inputconv, [size*stride_height,size*stride_width])\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size,], [padding_size, padding_size], [0, 0]])\n",
        "        inputconv_ = tf.pad(inputconv, paddings, \"REFLECT\")\n",
        "        conv = tf.contrib.layers.conv2d(inputconv_, num_features, [window_height, window_width], \n",
        "                                        [1, 1], padding='VALID', activation_fn=None, \n",
        "                                        weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                                        biases_initializer=tf.constant_initializer(0.0))\n",
        "        return conv\n",
        "\n",
        "      \n",
        "def build_resnet_block(input_res, num_features, padding_size=1, name=\"resnet\"):\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        out_res_1 = general_conv2d(input_res, num_features,\n",
        "                                   window_width=3, window_height=3,\n",
        "                                   stride_width=1, stride_height=1, \n",
        "                                   padding_size=1, name=\"c1\")\n",
        "        out_res_2 = general_conv2d(out_res_1, num_features,\n",
        "                                   window_width=3, window_height=3,\n",
        "                                   stride_width=1, stride_height=1, \n",
        "                                   padding_size=1, name=\"c2\")\n",
        "        return (out_res_2 + input_res)\n",
        "      \n",
        "      \n",
        "def _weights(layer_idx):\n",
        "    W = vgg_layers[0][layer_idx][0][0][2][0][0]\n",
        "    b = vgg_layers[0][layer_idx][0][0][2][0][1]\n",
        "    return W, b.reshape(b.size)\n",
        "  \n",
        "  \n",
        "def conv2d_relu(prev_layer, layer_idx, layer_name):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        # load parameters\n",
        "        W, b = _weights(layer_idx)\n",
        "        # initialize parameters\n",
        "        # W = tf.constant(W, name=\"weights\")\n",
        "        # b = tf.constant(b, name=\"bias\")\n",
        "        # convolution \n",
        "        conv2d = tf.nn.conv2d(input=prev_layer,\n",
        "                              filter=W,\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              padding=\"SAME\")\n",
        "        # activation\n",
        "        out = tf.nn.relu(conv2d + b)\n",
        "    return out\n",
        "    \n",
        "    \n",
        "def avgpool(prev_layer, layer_name):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        # average pooling\n",
        "        out = tf.nn.avg_pool(value=prev_layer,\n",
        "                             ksize=[1, 2, 2, 1],\n",
        "                             strides=[1, 2, 2, 1],\n",
        "                             padding=\"SAME\")\n",
        "    return out\n",
        "  \n",
        "  \n",
        "def gradient_panalty(real, fake, scope=\"discriminator\"):\n",
        "    alpha = tf.random_uniform(shape=[1], minval=0.0, maxval=1.0)\n",
        "    interpolated = alpha*real + (1.0 - alpha)*fake\n",
        "    logit, _ = build_discriminator(interpolated, reuse=tf.AUTO_REUSE, name=scope)\n",
        "    grad = tf.gradients(logit, interpolated)[0] # gradient of D(interpolated)\n",
        "    grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grad))) # l2 norm\n",
        "    GP = tf.reduce_mean(tf.square(grad_norm - 1.0))\n",
        "    return GP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z05qcryQjV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(input_gen, name=\"generator\"):\n",
        "    with tf.variable_scope(name):\n",
        "        # input_gen.shape = (1, 64, 64, 3)\n",
        "    \n",
        "        # Encoding\n",
        "        o_c1 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(input_gen, num_features=ngf, \n",
        "                              window_width=7, window_height=7, \n",
        "                              stride_width=1, stride_height=1, \n",
        "                              padding_size=3, name=\"c1\")))\n",
        "        # o_c1.shape = (1, 64, 64, 64)\n",
        "        \n",
        "        o_c2 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_c1, num_features=ngf*2, \n",
        "                              window_width=4, window_height=4, \n",
        "                              stride_width=2, stride_height=2, \n",
        "                              padding_size=1, name=\"c2\")))\n",
        "        # o_c2.shape = (1, 32, 32, 128)\n",
        "        \n",
        "        o_c3 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_c2, num_features=ngf*4, \n",
        "                              window_width=3, window_height=3, \n",
        "                              stride_width=2, stride_height=2, \n",
        "                              padding_size=1, name=\"c3\")))\n",
        "        # o_c3.shape = (1, 16, 16, 256)\n",
        "\n",
        "        # Transformation\n",
        "        o_r1 = build_resnet_block(o_c3, num_features=ngf*4, padding_size=1, name=\"r1\")\n",
        "        o_r2 = build_resnet_block(o_r1, num_features=ngf*4, padding_size=1, name=\"r2\")\n",
        "        o_r3 = build_resnet_block(o_r2, num_features=ngf*4, padding_size=1, name=\"r3\")\n",
        "        o_r4 = build_resnet_block(o_r3, num_features=ngf*4, padding_size=1, name=\"r4\")\n",
        "        o_r5 = build_resnet_block(o_r4, num_features=ngf*4, padding_size=1, name=\"r5\")\n",
        "        o_r6 = build_resnet_block(o_r5, num_features=ngf*4, padding_size=1, name=\"r6\")\n",
        "        # o_r6.shape = (1, 16, 16, 256)\n",
        "\n",
        "        #Decoding\n",
        "        o_d1 = tf.nn.relu(tf.contrib.layers.instance_norm(general_deconv2d(o_r6, num_features=ngf*2, \n",
        "                                window_width=3, window_height=3, \n",
        "                                stride_width=2, stride_height=2, \n",
        "                                padding_size=1, name=\"d1\")))\n",
        "        # o_d1.shape = (1, 32, 32, 128)\n",
        "        \n",
        "        o_d2 = tf.nn.relu(tf.contrib.layers.instance_norm(general_deconv2d(o_d1, num_features=ngf, \n",
        "                                window_width=3, window_height=3, \n",
        "                                stride_width=2, stride_height=2, \n",
        "                                padding_size=1, name=\"d2\")))\n",
        "        # o_d2.shape = (1, 64, 64, 64)\n",
        "        \n",
        "        gen_B = tf.contrib.layers.instance_norm(general_conv2d(o_d2, num_features=3, \n",
        "                               window_width=7, window_height=7, \n",
        "                               stride_width=1, stride_height=1, \n",
        "                               padding_size=3, name=\"c4\"))\n",
        "        # gen_B.shape = (1, 64, 64, 3)\n",
        "        \n",
        "        output = tf.nn.tanh(gen_B, \"t1\")\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP_V-ZSMQjTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(input_disc, name=\"discriminator\"):\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        # input_disc.shape = (1, 64, 64, 3)\n",
        "        o_c1 = tf.nn.leaky_relu(general_conv2d(input_disc, ndf, 4, 4, 2, 2, padding_size=1, name=\"c1\"), 0.2)\n",
        "        # o_c1 = tf.nn.dropout(o_c1, rate=0.2)\n",
        "        # o_c1.shape = (1, 32, 32, 32)\n",
        "        o_c2 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c1, ndf*2, 4, 4, 2, 2, padding_size=1, name=\"c2\"), 0.2))\n",
        "        # o_c2 = tf.nn.dropout(o_c2, rate=0.2)\n",
        "        # o_c2.shape = (1, 16, 16, 64)\n",
        "        o_c3 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c2, ndf*4, 4, 4, 2, 2, padding_size=1, name=\"c3\"), 0.2))\n",
        "        # o_c3 = tf.nn.dropout(o_c3, rate=0.2)\n",
        "        # o_c3.shape = (1, 8, 8, 128)\n",
        "        o_c4 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c3, ndf*8, 4, 4, 2, 2, padding_size=1, name=\"c4\"), 0.2))\n",
        "        # o_c4 = tf.nn.dropout(o_c4, rate=0.2)\n",
        "        # o_c4.shape = (1, 4, 4, 256)\n",
        "        \n",
        "        decision = tf.sigmoid(general_conv2d(o_c4, 1, 3, 3, 1, 1, padding_size=1, name=\"c5\"))\n",
        "        # decision.shape = (1, 4, 4, 1)\n",
        "\n",
        "        return decision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl9qQa7HgFYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pac_discriminator(input_disc_1, input_disc_2, name=\"discriminator\"):\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        input_disc = tf.concat([input_disc_1, input_disc_2], 3)\n",
        "        # input_disc.shape = (1, 64, 64, 6)\n",
        "        o_c1 = tf.nn.leaky_relu(general_conv2d(input_disc, ndf, 4, 4, 2, 2, padding_size=1, name=\"c1\"), 0.2)\n",
        "        # o_c1 = tf.nn.dropout(o_c1, rate=0.2)\n",
        "        # o_c1.shape = (1, 32, 32, 32)\n",
        "        o_c2 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c1, ndf*2, 4, 4, 2, 2, padding_size=1, name=\"c2\"), 0.2))\n",
        "        # o_c2 = tf.nn.dropout(o_c2, rate=0.2)\n",
        "        # o_c2.shape = (1, 16, 16, 64)\n",
        "        o_c3 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c2, ndf*4, 4, 4, 2, 2, padding_size=1, name=\"c3\"), 0.2))\n",
        "        # o_c3 = tf.nn.dropout(o_c3, rate=0.2)\n",
        "        # o_c3.shape = (1, 8, 8, 128)\n",
        "        o_c4 = tf.nn.leaky_relu(tf.contrib.layers.instance_norm(general_conv2d(o_c3, ndf*8, 4, 4, 2, 2, padding_size=1, name=\"c4\"), 0.2))\n",
        "        # o_c4 = tf.nn.dropout(o_c4, rate=0.2)\n",
        "        # o_c4.shape = (1, 4, 4, 256)\n",
        "        \n",
        "        decision = tf.sigmoid(general_conv2d(o_c4, 1, 4, 4, 1, 1, padding_size=2, name=\"c5\"))\n",
        "        # decision.shape = (1, 4, 4, 1)\n",
        "\n",
        "        return decision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uou39xaNRSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_extractor(input_image, name=\"extractor\"):\n",
        "    with tf.variable_scope(name):\n",
        "        conv1_1 = conv2d_relu(input_image, 0, \"conv1_1\")\n",
        "        conv1_2 = conv2d_relu(conv1_1, 2, \"conv1_2\")\n",
        "        avgpool1 = avgpool(conv1_2, \"avgpool1\")\n",
        "        conv2_1 = conv2d_relu(avgpool1, 5, \"conv2_1\")\n",
        "        conv2_2 = conv2d_relu(conv2_1, 7, \"conv2_2\")\n",
        "        avgpool2 = avgpool(conv2_2, \"avgpool2\")\n",
        "        conv3_1 = conv2d_relu(avgpool2, 10, \"conv3_1\")\n",
        "        conv3_2 = conv2d_relu(conv3_1, 12, \"conv3_2\")\n",
        "        conv3_3 = conv2d_relu(conv3_2, 14, \"conv3_3\")\n",
        "        conv3_4 = conv2d_relu(conv3_3, 16, \"conv3_4\")\n",
        "        avgpool3 = avgpool(conv3_4, \"avgpool3\")\n",
        "        conv4_1 = conv2d_relu(avgpool3, 19, \"conv4_1\")\n",
        "        conv4_2 = conv2d_relu(conv4_1, 21, \"conv4_2\")\n",
        "        conv4_3 = conv2d_relu(conv4_2, 23, \"conv4_3\")\n",
        "        conv4_4 = conv2d_relu(conv4_3, 25, \"conv4_4\")\n",
        "        avgpool4 = avgpool(conv4_4, \"avgpool4\")\n",
        "        conv5_1 = conv2d_relu(avgpool4, 28, \"conv5_1\")\n",
        "        conv5_2 = conv2d_relu(conv5_1, 30, \"conv5_2\")\n",
        "        return conv3_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_F6U_7bRpji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_extractor(input_image, name=\"extractor\"):\n",
        "        conv1_1 = conv2d_relu(input_image, 0, \"conv1_1\")\n",
        "        conv1_2 = conv2d_relu(conv1_1, 2, \"conv1_2\")\n",
        "        avgpool1 = avgpool(conv1_2, \"avgpool1\")\n",
        "        conv2_1 = conv2d_relu(avgpool1, 5, \"conv2_1\")\n",
        "        conv2_2 = conv2d_relu(conv2_1, 7, \"conv2_2\")\n",
        "        avgpool2 = avgpool(conv2_2, \"avgpool2\")\n",
        "        conv3_1 = conv2d_relu(avgpool2, 10, \"conv3_1\")\n",
        "        conv3_2 = conv2d_relu(conv3_1, 12, \"conv3_2\")\n",
        "        conv3_3 = conv2d_relu(conv3_2, 14, \"conv3_3\")\n",
        "        conv3_4 = conv2d_relu(conv3_3, 16, \"conv3_4\")\n",
        "        avgpool3 = avgpool(conv3_4, \"avgpool3\")\n",
        "        conv4_1 = conv2d_relu(avgpool3, 19, \"conv4_1\")\n",
        "        conv4_2 = conv2d_relu(conv4_1, 21, \"conv4_2\")\n",
        "        conv4_3 = conv2d_relu(conv4_2, 23, \"conv4_3\")\n",
        "        conv4_4 = conv2d_relu(conv4_3, 25, \"conv4_4\")\n",
        "        avgpool4 = avgpool(conv4_4, \"avgpool4\")\n",
        "        conv5_1 = conv2d_relu(avgpool4, 28, \"conv5_1\")\n",
        "\n",
        "        return conv1_1, conv2_1, conv3_1, conv4_1, conv5_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U7yT4f5qg41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def _content_extractor(input_image, name=\"extractor\"):\n",
        "    with tf.variable_scope(name):\n",
        "        # input_image.shape = (1, 64, 64, 3)\n",
        "      \n",
        "        # window size = 3?\n",
        "        o_c1 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(input_image, num_features=64, \n",
        "                   window_height=3, window_width=3, \n",
        "                   stride_height=1, stride_width=1, \n",
        "                   padding_size=1, name=\"c1\")))\n",
        "        # o_c1.shape = (1, 64, 64, 64)\n",
        "        \n",
        "        o_c2 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_c1, num_features=64*2, \n",
        "                   window_height=4, window_width=4, \n",
        "                   stride_height=2, stride_width=2, \n",
        "                   padding_size=1, name=\"c2\")))\n",
        "        # o_c2.shape = (1, 32, 32, 128)\n",
        "        \n",
        "        o_c3 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_c2, num_features=64*2, \n",
        "                   window_height=3, window_width=3, \n",
        "                   stride_height=1, stride_width=1, \n",
        "                   padding_size=1, name=\"c3\")))\n",
        "        # o_c3.shape = (1, 32, 32, 128)\n",
        "        \n",
        "        o_c4 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_c3, num_features=64*4, \n",
        "                   window_height=4, window_width=4, \n",
        "                   stride_height=2, stride_width=2, \n",
        "                   padding_size=1, name=\"c4\")))\n",
        "        # o_c4.shape = (1, 16, 16, 256)\n",
        "        \n",
        "        o_r1 = build_resnet_block(o_c4, num_features=ngf*4, padding_size=1, name=\"r1\")\n",
        "        # o_r1.shape = (1, 16, 16, 256)\n",
        "        \n",
        "        o_c5 = tf.nn.relu(tf.contrib.layers.instance_norm(general_conv2d(o_r1, num_features=64*8, \n",
        "                   window_height=4, window_width=4, \n",
        "                   stride_height=2, stride_width=2, \n",
        "                   padding_size=1, name=\"c5\")))\n",
        "        # o_c5.shape = (1, 8, 8, 512)\n",
        "        \n",
        "        # window size = 3?\n",
        "        o_c6 = tf.contrib.layers.instance_norm(general_conv2d(o_c5, num_features=64*8, \n",
        "                   window_height=3, window_width=3, \n",
        "                   stride_height=1, stride_width=1, \n",
        "                   padding_size=1, name=\"c6\"))\n",
        "        # o_c6.shape = (1, 8, 8, 512)\n",
        "        \n",
        "        return o_c6\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUThERqhPw8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIlLI8GrQBju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_A\")\n",
        "input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_B\")\n",
        "\n",
        "buffer_gen_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_A\")\n",
        "buffer_gen_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_B\")\n",
        "\n",
        "with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE) as scope:\n",
        "  \n",
        "    gen_B = build_generator(input_A, name=\"generator_AtoB\")\n",
        "    gen_A = build_generator(input_B, name=\"generator_BtoA\")\n",
        "\n",
        "    dec_A = build_discriminator(input_A, name=\"discriminator_A\")\n",
        "    dec_B = build_discriminator(input_B, name=\"discriminator_B\")\n",
        "    \n",
        "    input_A_content = content_extractor(input_A, name=\"extractor\")\n",
        "    input_B_content = content_extractor(input_B, name=\"extractor\")\n",
        "    \n",
        "    input_A_style_1, input_A_style_2, input_A_style_3, input_A_style_4, input_A_style_5 = style_extractor(input_A, name=\"sextractor\")\n",
        "    input_B_style_1, input_B_style_2, input_B_style_3, input_B_style_4, input_B_style_5 = style_extractor(input_B, name=\"sextractor\")\n",
        "\n",
        "    dec_gen_A = build_discriminator(gen_A, \"discriminator_A\")\n",
        "    dec_gen_B = build_discriminator(gen_B, \"discriminator_B\")\n",
        "\n",
        "    cyc_A = build_generator(gen_B, \"generator_BtoA\")\n",
        "    cyc_B = build_generator(gen_A, \"generator_AtoB\")\n",
        "    \n",
        "    dec_buffer_gen_A = build_discriminator(buffer_gen_A, \"discriminator_A\")\n",
        "    dec_buffer_gen_B = build_discriminator(buffer_gen_B, \"discriminator_B\")\n",
        "    \n",
        "    gen_A_content = content_extractor(gen_A, name=\"extractor\")\n",
        "    gen_B_content = content_extractor(gen_B, name=\"extractor\")\n",
        "    \n",
        "    gen_A_style_1, gen_A_style_2, gen_A_style_3, gen_A_style_4, gen_A_style_5 = style_extractor(gen_A, name=\"sextractor\")\n",
        "    gen_B_style_1, gen_B_style_2, gen_B_style_3, gen_B_style_4, gen_B_style_5 = style_extractor(gen_B, name=\"sextractor\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVFwaAYfQjQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_A\")\n",
        "input_A_2 = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_A_2\")\n",
        "input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_B\")\n",
        "input_B_2 = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"input_B_2\")\n",
        "\n",
        "buffer_gen_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_A\")\n",
        "buffer_gen_A_2 = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_A_2\")\n",
        "buffer_gen_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_B\")\n",
        "buffer_gen_B_2 = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_depth], name=\"buffer_gen_B_2\")\n",
        "\n",
        "with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE) as scope:\n",
        "  \n",
        "    gen_B = build_generator(input_A, name=\"generator_AtoB\")\n",
        "    gen_B_2 = build_generator(input_A_2, name=\"generator_AtoB\")\n",
        "    gen_A = build_generator(input_B, name=\"generator_BtoA\")\n",
        "    gen_A_2 = build_generator(input_B_2, name=\"generator_BtoA\")\n",
        "\n",
        "    dec_A = pac_discriminator(input_A, input_A_2, name=\"discriminator_A\")\n",
        "    dec_B = pac_discriminator(input_B, input_B_2, name=\"discriminator_B\")\n",
        "    \n",
        "    input_A_content = content_extractor(input_A, name=\"extractor\")\n",
        "    input_B_content = content_extractor(input_B, name=\"extractor\")\n",
        "    \n",
        "    input_A_style_1, input_A_style_2, input_A_style_3, input_A_style_4, input_A_style_5 = style_extractor(input_A, name=\"sextractor\")\n",
        "    input_B_style_1, input_B_style_2, input_B_style_3, input_B_style_4, input_B_style_5 = style_extractor(input_B, name=\"sextractor\")\n",
        "\n",
        "    dec_gen_A = pac_discriminator(gen_A, gen_A_2, \"discriminator_A\")\n",
        "    dec_gen_B = pac_discriminator(gen_B, gen_B_2, \"discriminator_B\")\n",
        "\n",
        "    cyc_A = build_generator(gen_B, \"generator_BtoA\")\n",
        "    cyc_B = build_generator(gen_A, \"generator_AtoB\")\n",
        "    \n",
        "    dec_buffer_gen_A = pac_discriminator(buffer_gen_A, buffer_gen_A_2, \"discriminator_A\")\n",
        "    dec_buffer_gen_B = pac_discriminator(buffer_gen_B, buffer_gen_B_2, \"discriminator_B\")\n",
        "    \n",
        "    gen_A_content = content_extractor(gen_A, name=\"extractor\")\n",
        "    gen_B_content = content_extractor(gen_B, name=\"extractor\")\n",
        "    \n",
        "    gen_A_style_1, gen_A_style_2, gen_A_style_3, gen_A_style_4, gen_A_style_5 = style_extractor(gen_A, name=\"sextractor\")\n",
        "    gen_B_style_1, gen_B_style_2, gen_B_style_3, gen_B_style_4, gen_B_style_5 = style_extractor(gen_B, name=\"sextractor\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMfw5eluQjNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator loss\n",
        "D_A_loss_1 = tf.reduce_mean(tf.squared_difference(dec_A,1))\n",
        "D_B_loss_1 = tf.reduce_mean(tf.squared_difference(dec_B,1))\n",
        "\n",
        "D_A_loss_2 = tf.reduce_mean(tf.square(dec_buffer_gen_A))\n",
        "D_B_loss_2 = tf.reduce_mean(tf.square(dec_buffer_gen_B))\n",
        "\n",
        "d_loss_A = (D_A_loss_1 + D_A_loss_2)/2\n",
        "d_loss_B = (D_B_loss_1 + D_B_loss_2)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ8C2cPfQjLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cyclic loss (L1)\n",
        "cyc_loss = tf.reduce_mean(tf.abs(input_A-cyc_A)) + tf.reduce_mean(tf.abs(input_B-cyc_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOmd-zceQjIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# content loss (L1)\n",
        "content_loss_BtoA = tf.reduce_mean(tf.abs(input_B_content-gen_A_content))\n",
        "content_loss_AtoB = tf.reduce_mean(tf.abs(input_A_content-gen_B_content))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn297fHFSeCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# style loss (L1)\n",
        "style_loss_A = 0.5*tf.reduce_mean(tf.abs(input_A_style_1-gen_A_style_1))+tf.reduce_mean(tf.abs(input_A_style_2-gen_A_style_2))+1.5*tf.reduce_mean(tf.abs(input_A_style_3-gen_A_style_3))+3*tf.reduce_mean(tf.abs(input_A_style_4-gen_A_style_4))+4*tf.reduce_mean(tf.abs(input_A_style_5-gen_A_style_5))\n",
        "style_loss_B = 0.5*tf.reduce_mean(tf.abs(input_B_style_1-gen_B_style_1))+tf.reduce_mean(tf.abs(input_B_style_2-gen_B_style_2))+1.5*tf.reduce_mean(tf.abs(input_B_style_3-gen_B_style_3))+3*tf.reduce_mean(tf.abs(input_B_style_4-gen_B_style_4))+4*tf.reduce_mean(tf.abs(input_B_style_5-gen_B_style_5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DibGbs7H7HFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variation loss\n",
        "var_loss_A = tf.image.total_variation(gen_A)\n",
        "var_loss_B = tf.image.total_variation(gen_B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC-62X4CQjFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator loss\n",
        "g_loss_BtoA = tf.reduce_mean(tf.squared_difference(dec_gen_A,1))\n",
        "g_loss_AtoB = tf.reduce_mean(tf.squared_difference(dec_gen_B,1))\n",
        "\n",
        "g_loss_BtoA = g_loss_BtoA + 10*cyc_loss + 5*content_loss_BtoA + 0.0001*var_loss_A + 0.05*style_loss_A\n",
        "g_loss_AtoB = g_loss_AtoB + 10*cyc_loss + 5*content_loss_AtoB + 0.0001*var_loss_B + 0.05*style_loss_B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEfX5h79QjDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "lr = tf.placeholder(tf.float32, shape=[], name=\"lr\")\n",
        "\n",
        "model_vars = tf.trainable_variables()\n",
        "d_A_vars = [var for var in model_vars if 'discriminator_A' in var.name]\n",
        "g_AtoB_vars = [var for var in model_vars if 'generator_AtoB' in var.name]\n",
        "d_B_vars = [var for var in model_vars if 'discriminator_B' in var.name]\n",
        "g_BtoA_vars = [var for var in model_vars if 'generator_BtoA' in var.name]\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(lr, beta1=0.5)\n",
        "d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
        "d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
        "g_AtoB_trainer = optimizer.minimize(g_loss_AtoB, var_list=g_AtoB_vars)\n",
        "g_BtoA_trainer = optimizer.minimize(g_loss_BtoA, var_list=g_BtoA_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A40qqs8AQjAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def instance_noise():\n",
        "    return np.random.uniform(-1.0, 1.0, [1,64,64,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLHuYgfOQi9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Painting', 'rb') as f:\n",
        "    A_input = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Photo', 'rb') as f:\n",
        "    B_input = pickle.load(f)    \n",
        "    \n",
        "A_input = np.array(A_input)\n",
        "B_input = np.array(B_input)\n",
        "A_input = A_input/127.5-1\n",
        "B_input = B_input/127.5-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oNR2gdYQdd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    if to_restore:\n",
        "        # chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
        "        saver.restore(sess, '/content/gdrive/My Drive/MSc ML/0091/64x64/outputs/output8/checkpoint/cyclegan-75')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWH1uIrDQi6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    if to_restore:\n",
        "        # chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
        "        saver.restore(sess, '/content/gdrive/My Drive/MSc ML/0091/64x64/checkpoint/model-0')\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Buffer/A', 'rb') as f:\n",
        "            gen_A_buffer = pickle.load(f)\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Buffer/B', 'rb') as f:\n",
        "            gen_B_buffer = pickle.load(f)\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Loss/gA2B', 'rb') as f:\n",
        "            g_loss_AtoB_list = pickle.load(f)\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Loss/gB2A', 'rb') as f:\n",
        "            g_loss_BtoA_list = pickle.load(f)\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Loss/dA', 'rb') as f:\n",
        "            d_loss_A_list = pickle.load(f)\n",
        "        with open('/content/gdrive/My Drive/MSc ML/0091/64x64/Loss/dB', 'rb') as f:\n",
        "            d_loss_B_list = pickle.load(f)\n",
        "    else:\n",
        "        gen_A_buffer = []\n",
        "        gen_B_buffer = []\n",
        "        g_loss_AtoB_list = []\n",
        "        g_loss_BtoA_list = []\n",
        "        d_loss_A_list = []\n",
        "        d_loss_B_list = []\n",
        "      \n",
        "    for epoch in range(0, 200):\n",
        "        print('epoch' + str(epoch))\n",
        "        # Define the learning rate schedule. The learning rate is kept constant upto 100 epochs and then linearly decayed to 0.\n",
        "        if(epoch < 100) :\n",
        "            # learning rate = 0.0002\n",
        "            curr_lr = 0.0002\n",
        "        else:\n",
        "            curr_lr = 0.0002 - 0.0002*(epoch-99)/100\n",
        "            \n",
        "        loss_g_A2B = 0 \n",
        "        loss_g_B2A = 0\n",
        "        loss_d_A = 0\n",
        "        loss_d_B = 0\n",
        "    \n",
        "        # Running the training loop for all batches\n",
        "        for ptr in range(0, 2000):\n",
        "            \n",
        "            j = np.random.randint(1000)\n",
        "            m = np.random.randint(1000)\n",
        "            k = np.random.randint(5000)\n",
        "            n = np.random.randint(5000)\n",
        "            \n",
        "            # Train generator G_A->B\n",
        "            _, gen_B_temp, g_loss_AtoB_temp = sess.run([g_AtoB_trainer, gen_B, g_loss_AtoB],\n",
        "                                     feed_dict={input_A:(A_input[j]), input_A_2:(A_input[m]), input_B:(B_input[k]), input_B_2:(B_input[n]), lr:curr_lr})\n",
        "\n",
        "            loss_g_A2B += g_loss_AtoB_temp/2500\n",
        "            \n",
        "            gen_B_buffer.append(gen_B_temp)\n",
        "            if len(gen_B_buffer) > 50:\n",
        "                del gen_B_buffer[np.random.randint(50)]\n",
        "\n",
        "            which = np.random.randint(len(gen_B_buffer))\n",
        "            B_buffer_gen = gen_B_buffer[which]\n",
        "            which = np.random.randint(len(gen_B_buffer))\n",
        "            B_buffer_gen_2 = gen_B_buffer[which]\n",
        "\n",
        "            # We need gen_B_temp because to calculate the error in training D_B\n",
        "            _, d_loss_B_temp = sess.run([d_B_trainer, d_loss_B], feed_dict={input_B:((0.5+epoch/400)*B_input[k]+(0.5-epoch/400)*instance_noise()), \n",
        "                                                                            input_B_2:((0.5+epoch/400)*B_input[n]+(0.5-epoch/400)*instance_noise()), \n",
        "                                                                            buffer_gen_B:(0.5+epoch/400)*B_buffer_gen+(0.5-epoch/400)*instance_noise(), \n",
        "                                                                            buffer_gen_B_2:(0.5+epoch/400)*B_buffer_gen_2+(0.5-epoch/400)*instance_noise(), lr:curr_lr})\n",
        "\n",
        "            loss_d_B += d_loss_B_temp/2000\n",
        "\n",
        "            # Same for G_B->A and D_A as follow\n",
        "            _, gen_A_temp, g_loss_BtoA_temp = sess.run([g_BtoA_trainer, gen_A, g_loss_BtoA],\n",
        "                                     feed_dict={input_A:(A_input[j]), input_A_2:(A_input[m]), input_B:(B_input[k]), input_B_2:(B_input[n]), lr:curr_lr})\n",
        "\n",
        "            loss_g_B2A += g_loss_BtoA_temp/2000\n",
        "\n",
        "            gen_A_buffer.append(gen_A_temp)\n",
        "            if len(gen_A_buffer) > 50:\n",
        "                del gen_A_buffer[np.random.randint(50)]\n",
        "\n",
        "            which = np.random.randint(len(gen_A_buffer))\n",
        "            A_buffer_gen = gen_A_buffer[which]\n",
        "            which = np.random.randint(len(gen_A_buffer))\n",
        "            A_buffer_gen_2 = gen_A_buffer[which]\n",
        "\n",
        "            _, d_loss_A_temp = sess.run([d_A_trainer, d_loss_A], feed_dict={input_A:((0.5+epoch/400)*A_input[j]+(0.5-epoch/400)*instance_noise()), \n",
        "                                                                            input_A_2:((0.5+epoch/400)*A_input[m]+(0.5-epoch/400)*instance_noise()), \n",
        "                                                                            buffer_gen_A:(0.5+epoch/400)*A_buffer_gen+(0.5-epoch/400)*instance_noise(), \n",
        "                                                                            buffer_gen_A_2:(0.5+epoch/400)*A_buffer_gen_2+(0.5-epoch/400)*instance_noise(), lr:curr_lr})\n",
        "            \n",
        "            loss_d_A += d_loss_A_temp/2500\n",
        "            \n",
        "        g_loss_AtoB_list.append(loss_g_A2B)\n",
        "        g_loss_BtoA_list.append(loss_g_B2A)\n",
        "        d_loss_A_list.append(loss_d_A)\n",
        "        d_loss_B_list.append(loss_d_B)\n",
        "        print(' loss of generatorAtoB' + str(loss_g_A2B))\n",
        "        print(' loss of generatorBtoA' + str(loss_g_B2A))\n",
        "        print(' loss of discriminatorA' + str(loss_d_A))\n",
        "        print(' loss of discriminatorB' + str(loss_d_B))\n",
        "            \n",
        "                \n",
        "        # save training images\n",
        "        if epoch%5==0:\n",
        "          \n",
        "            saver.save(sess, check_dir + \"cyclegan\", global_step=epoch)\n",
        "            for i in range(6):\n",
        "                gen_A_temp, gen_B_temp, cyc_A_temp, cyc_B_temp = sess.run([gen_A, gen_B, cyc_A, cyc_B], feed_dict={input_A:A_input[i], input_B:B_input[i]})\n",
        "                Image.fromarray(((gen_A_temp[0]+1)*127.5).astype(np.uint8)).save(\"/content/gdrive/My Drive/MSc ML/0091/64x64/output9/fakeA_\"+ str(i) + \"_\" + str(epoch), 'JPEG', quality=90)\n",
        "                Image.fromarray(((gen_B_temp[0]+1)*127.5).astype(np.uint8)).save(\"/content/gdrive/My Drive/MSc ML/0091/64x64/output9/fakeB_\"+ str(i) + \"_\" + str(epoch), 'JPEG', quality=90)\n",
        "                Image.fromarray(((cyc_A_temp[0]+1)*127.5).astype(np.uint8)).save(\"/content/gdrive/My Drive/MSc ML/0091/64x64/output9/cycA_\"+ str(i) + \"_\" + str(epoch), 'JPEG', quality=90)\n",
        "                Image.fromarray(((cyc_B_temp[0]+1)*127.5).astype(np.uint8)).save(\"/content/gdrive/My Drive/MSc ML/0091/64x64/output9/cycB_\"+ str(i) + \"_\" + str(epoch), 'JPEG', quality=90)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adEZmBE0jeOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}